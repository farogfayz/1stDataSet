{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 5761,
     "status": "ok",
     "timestamp": 1699952396036,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "LNyyzTo2bpi7",
    "outputId": "30ed1713-c0fa-4e2e-938e-a59274e24b37",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://1stdataset.s3.us-east-2.amazonaws.com/CSVs/CSV-03-11/03-11/LDAP.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1699952396816,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "ePTb3VxodcUB",
    "outputId": "268eaa3e-e351-4aa3-a10c-b9c24eb434d5"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 2858,
     "status": "ok",
     "timestamp": 1699952399668,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "Z-GfV_NTdvRu",
    "outputId": "47175fbf-66a9-412b-c97a-165948efb106"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Pre-process the data\n",
    "# Encode categorical features (e.g., IP addresses)\n",
    "encoder = LabelEncoder()\n",
    "data[' Source IP'] = encoder.fit_transform(data[' Source IP'])\n",
    "data[' Destination IP'] = encoder.fit_transform(data[' Destination IP'])\n",
    "data[' Timestamp'] = pd.to_datetime(data[' Timestamp']).astype(np.int64)\n",
    "data[' Label'] = encoder.fit_transform(data[' Label'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1699952400766,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "wIIMf8inhO42",
    "outputId": "ae89cc88-b699-440e-fa20-aabf7c2220ed"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "try:\n",
    "  data = data.drop(['Unnamed: 0', 'Flow ID', 'SimillarHTTP'], axis=1)\n",
    "except:\n",
    "  print('Columns are dropped already')\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 100000\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data[' Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data[data[' Label'] != minority_class]\n",
    "minority_samples = data[data[' Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Combine the sampled majority class samples and minority class samples\n",
    "balanced_data = pd.concat([majority_samples_sampled, minority_samples], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1699952400767,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "s2F2L7fRilJE",
    "outputId": "74fd2d4e-7dd2-478b-f30f-e115299fb700"
   },
   "outputs": [],
   "source": [
    "balanced_data[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1699952400768,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "Lf4wpJ_6isxO",
    "outputId": "5c5b720e-10eb-46ba-d20e-fc68e98676d5"
   },
   "outputs": [],
   "source": [
    "data[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1699952400770,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "UHppj_hyn6XF",
    "outputId": "3731a4fb-47af-4365-85aa-d1ab847f215c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is named 'data'\n",
    "correlation = balanced_data[' Inbound'].corr(balanced_data[' Label'])\n",
    "print(\"Correlation between 'Inbound' and 'Label':\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1699952400772,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "jk5jvQ4MoOBs",
    "outputId": "87ee3d8f-92e1-4616-9bd3-630d34dc2824"
   },
   "outputs": [],
   "source": [
    "balanced_data[' Inbound'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1699952401773,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "9LWbKuBpp19B",
    "outputId": "596093dd-cf63-4f20-debc-1cc09b475ec8"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataframe is named 'df'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=balanced_data, x=' Inbound', hue=' Label')\n",
    "plt.title('Frequency of Inbound with Label as Hue')\n",
    "plt.xlabel('Inbound')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1699952402310,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "8KipWztuqCCu",
    "outputId": "8a476c3c-a088-4f97-9d49-0869631eb5d0"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataframe is named 'df'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=balanced_data, x=' Label', hue=' Inbound')\n",
    "plt.title('Frequency of Label with Inbound as Hue')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1699952402768,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "yoxvG-3cqfCK",
    "outputId": "d54cd82a-a06a-4abd-e432-793197fb43ed"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataframe is named 'df'\n",
    "inbound_label_counts = balanced_data.groupby([' Inbound', ' Label']).size().reset_index(name='Count')\n",
    "total_counts = balanced_data.groupby([' Inbound']).size().reset_index(name='Total_Count')\n",
    "\n",
    "inbound_label_counts = inbound_label_counts.merge(total_counts, on=' Inbound')\n",
    "inbound_label_counts['Percentage'] = (inbound_label_counts['Count'] / inbound_label_counts['Total_Count']) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=inbound_label_counts, x=' Inbound', y='Percentage', hue=' Label')\n",
    "plt.title('Frequency of Inbound with Label as Hue (Percentage)')\n",
    "plt.xlabel('Inbound')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1699952402769,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "rjkxk3cLq77X",
    "outputId": "e8367b2e-222e-406f-fe30-fcd4f2e50f5b"
   },
   "outputs": [],
   "source": [
    "inbound_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r02qZDIiffV0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into train and test sets\n",
    "X = balanced_data.drop([' Inbound',' Label'], axis=1)\n",
    "y = balanced_data[' Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1699952403084,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "Y2vIbHbtgpxl",
    "outputId": "3dd9a303-95dc-4a91-a190-f3894b2728cf"
   },
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1699952403398,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "ApWxjYU2j_49",
    "outputId": "a0639944-c3d9-47fd-f138-1261a930657e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_data_issues(data):\n",
    "    # Check for NaN values\n",
    "    if data.isnull().values.any():\n",
    "        print(\"There are NaN values in the dataset.\")\n",
    "\n",
    "    # Check for infinite values\n",
    "    if np.isinf(data).values.any():\n",
    "        print(\"There are infinite values in the dataset.\")\n",
    "\n",
    "    # Check for extremely large values\n",
    "    max_value = data.max().max()\n",
    "    if max_value > np.finfo(np.float64).max:\n",
    "        print(f\"There are values too large for dtype('float64') in the dataset. Max value: {max_value}\")\n",
    "\n",
    "    # Check for extremely small values\n",
    "    min_value = data.min().min()\n",
    "    if min_value < np.finfo(np.float64).min:\n",
    "        print(f\"There are values too small for dtype('float64') in the dataset. Min value: {min_value}\")\n",
    "\n",
    "# Check the training and testing data for any issues\n",
    "check_data_issues(X_train)\n",
    "check_data_issues(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMmPRzjckl35"
   },
   "outputs": [],
   "source": [
    "# Replace infinity values with NaN\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute NaN values with the mean of the corresponding column\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Now, standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIK-cU-ifncT"
   },
   "outputs": [],
   "source": [
    "# # Handle class imbalance using SMOTE\n",
    "# smote = SMOTE()\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AV4SkExLf-Eb"
   },
   "outputs": [],
   "source": [
    "# # Train and evaluate machine learning models\n",
    "# models = {\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Support Vector Machine\": SVC()\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"{name}:\")\n",
    "#     print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "#     print(f\"F1 score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32847,
     "status": "ok",
     "timestamp": 1699952436554,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "OeH-ZlcZr0gX",
    "outputId": "7a6bb373-7cd7-4865-c43f-7dfd764ba288"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "\n",
    "# Train and evaluate machine learning models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append the metrics to the DataFrame\n",
    "    model_comparison = model_comparison.append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1699952436557,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "T-BFrAk1k8GR",
    "outputId": "1e8efaf4-24e8-48ec-beb8-70e6effee121"
   },
   "outputs": [],
   "source": [
    "feature_columns = X.columns\n",
    "\n",
    "# Get the Random Forest model from the 'models' dictionary\n",
    "random_forest_model = models['Random Forest']\n",
    "\n",
    "# Get feature importances\n",
    "importances = random_forest_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with the feature names and their corresponding importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances DataFrame\n",
    "# Filter the DataFrame to show only features with non-zero importance\n",
    "non_zero_importances = feature_importances[feature_importances['Importance'] > 0]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "non_zero_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1699952436996,
     "user": {
      "displayName": "Farog Fayz",
      "userId": "10363686322394617612"
     },
     "user_tz": -120
    },
    "id": "Rp7wReGM1cJO",
    "outputId": "45ce681b-6895-4a2f-e606-da3ece2aca67"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Choose the model you want to use, for example, Random Forest\n",
    "model = models[\"Random Forest\"]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn's heatmap\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4Ygo0ir2yq5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
